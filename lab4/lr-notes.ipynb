{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcularea functiei de cost pentru regresia logistica multinomiala\n",
    "\n",
    "Formula costului pentru $\\theta$ matrice de k linii si n coloane este un scalar cu expresia data in curs:\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\left[ \n",
    "    \\sum_{j=1}^{m} \\sum_{l=1}^{k} I(y^{(j)} = l) \\cdot\n",
    "    log \\frac{\n",
    "        exp( \\theta_l^t x^{(j)} )\n",
    "    }{\n",
    "        \\sum_{h=1}^{k} exp( \\theta_h^t x^{(j)} )\n",
    "    } \\right]$$\n",
    "    \n",
    "$x$ este matrice de m x n si \n",
    "\n",
    "$\\theta$ matrice de k x n.\n",
    "\n",
    "Daca ne referim la $x^{(j)}$ vorbim de linia j din matricea $x$, care linie are n elemente, iar daca ne referim la $\\theta_l$ discutia este despre linia l din matricea $\\theta$, care linie are, iarasi, tot n elemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideram calculul termenului logaritm din relatia anterioara dar folosind relatiile matriciale. Termenul $\\theta_l^t x^{(j)}$, care este un scalar, poate fi calculat matricial cu produsul matricial $x \\cdot \\theta^t$, care va avea dimensiunea de m x k.\n",
    "\n",
    "In particular, se observa ca dupa exponentierea matricei rezultat, este necesar sa calculam suma pe fiecare coloana in parte (sum cu axis = 1). Pe urma impartim fiecare element din matricea rezultat cu suma de pe coloana sa astfel calculata. Este o simpla impartire element-cu-element cu vectorul de m elemente sume calculat anterior (se face broadcast de la forma m x 1 la forma m x k).\n",
    "\n",
    "Mai departe, pentru ca matricea logaritm de m x k sa fie compatibila cu I(.) (functia indicator), trebuie sa scriem functia indicator ca o matrice m x k, in care fiecare linie este un \"one-hot encoding\" pentru eticheta pattern-ului $x^{(j)}$. \n",
    "\n",
    "Astfel extinsa, functia indicator de m x k se poate inmulti element-cu-elemnet cu matricea logaritm. Rezultatul este tot o matrice m x k. Costul scalar J(.) se obtine prin sumarea pe linii (np.sum, axis = 1) si pe urma prin sumarea pe coloane (a ramas o singura linie), sau, mai rapid, prin folosirea functiei np.average pe coloane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcularea gradientului pentru regresia logistica multinomiala\n",
    "\n",
    "Pornim de la expresia algebirca a gradientului in raport cu directiile date de vectorul $\\theta_l$ (care are n componente, unde l parcurge 1..k, cum am vazut mai sus):\n",
    "\n",
    "$$\\nabla_{\\theta_l}(\\theta) = - \\frac{1}{m} \\sum_{j=1}^{m} \\left[\n",
    "    x^{(j)} \\left(\n",
    "        I(y^{(j)} = l) - \\frac{\n",
    "            exp( \\theta_l^t x^{(j)} )\n",
    "        }{\n",
    "            \\sum_{h=1}^{k} exp( \\theta_h^t x^{(j)} )\n",
    "        }\n",
    "    \\right)\n",
    "\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argumentul de sub logaritmul din prima relatie este functia softmax(.), pe care am expandat-o aici. Dimensiunea matricii lui softmax() este m x k.\n",
    "\n",
    "Pentru a o face compatibila cu functia indicator, I(.) este scrisa, ca mai sus, cu forma m x k, unde fiecare linie este un one-hot encoding. Mai departe, ne referim la diferenta I(.) - softmax(.) ca la matricea \"ip\", de forma m x k.\n",
    "\n",
    "Acum urmeaza partea interesanta. Fiecare linie $x^{(j)}$ de n elemente se inmulteste cu fiecare din elementele liniei j din matricea ip. Fie matricile x si ip astfel:\n",
    "\n",
    "$$ \n",
    "x = \\left[ \\begin{array}{cccc}\n",
    "x_1^{(1)} & x_2^{(1)} & \\dots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & x_2^{(2)} & \\dots & x_n^{(2)} \\\\\n",
    "\\dots & \\dots & \\dots & \\dots \\\\\n",
    "x_1^{(m)} & x_2^{(m)} & \\dots & x_n^{(m)} \\\\\n",
    "\\end{array} \\right]\n",
    "\\qquad \n",
    "ip = \\left[ \\begin{array}{cccc}\n",
    "ip_1^{(1)} & ip_2^{(1)} & \\dots & ip_k^{(1)} \\\\\n",
    "ip_1^{(2)} & ip_2^{(2)} & \\dots & ip_k^{(2)} \\\\\n",
    "\\dots & \\dots & \\dots & \\dots \\\\\n",
    "ip_1^{(m)} & ip_2^{(m)} & \\dots & ip_k^{(m)} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "Fiecare din elementele liniei j din matricea x se inmulteste asadar cu fiecare element de pe linia corespondenta j din matricea ip. Vizualizati urmatorul lucru: matricea x se \"trasforma\" intr-un tensor tridimensional, in care fiecare element capata o \"adancime\" de k elemente. Mai departe, pe acest tensor 3D se face o suma intre toate cele m linii (prima dimensiune), si rezulta o matrice n x k.\n",
    "\n",
    "\n",
    "O varianta mai simpla, pentru ca tot se face sumare pe linii, este sa inmultim matricial x si ip. Iata mai jos, pe un exemplu, cele doua strategii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alegem dimensiunile sa fie diferite\n",
    "m = 3 \n",
    "n = 4\n",
    "k = 2\n",
    "\n",
    "# matricea x este de forma (m x n)\n",
    "x = np.array([[1, 2, 3, 4], [2, 1, -1, 2], [3, 1, 4, -2]])\n",
    "assert(x.shape == (m, n))\n",
    "\n",
    "# matricea ip este de forma (m x k)\n",
    "ip = np.array([[2, 1], [3, 4], [5, 6]])\n",
    "assert(ip.shape == (m, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategia folosind tensori 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiem cele doua matrici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = x.copy()\n",
    "ip_ = ip.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facem extindere la 3 dimensiuni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = np.reshape(x_, (m, 1, n))\n",
    "ip_ = np.reshape(ip_, (m, k, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inmultim element cu element cele doua matrici. Deoarece dimensiunile nu coincid, se va face broadcasting pe dimensiunile cu valoare 1.\n",
    "\n",
    "Consideram 3 dimensiuni, \"linii\", \"coloane\" si \"adancimi\".\n",
    "\n",
    "Pentru x, deoarece este o singura coloana, planul de linii si adancimi se replica pentru k coloane. Pentru ip, deoarece exista o singura adancime, planul de linii si coloane se replica pentru n adancimi. (incercati sa vizualizati acest lucru)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_ = x_ * ip_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai departe, sumam intre linii (axa 0). Ca urmare, o sa ramana doar un plan orizontal, cu o singura linie de coloane si adancimi. Acesta este theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_ = np.sum(delta_, axis=0)\n",
    "delta_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategia folosind inmultirea de matrici\n",
    "\n",
    "Mai simplu, inglobam si suma dupa m si folosim produsul matricial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = np.dot(ip.T, x)\n",
    "delta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparam rezultatele obtinut din ambele strategii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(delta == delta_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
